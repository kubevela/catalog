# Code generated by KubeVela templates. DO NOT EDIT. Please edit the original cue file.
# Definition source cue file: vela-templates/definitions/internal/training.cue
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  annotations:
    definition.oam.dev/description: Model Training uses KubeFlow training operator to train models
  name: model-training
  namespace: vela-system
spec:
  schematic:
    cue:
      template: |
        kindMap: {
        	tensorflow: "TFJob"
        	pytorch:    "PyTorchJob"
        	mxnet:      "MXJob"
        	mpi:        "MPIJob"
        	xgboost:    "XGBoostJob"
        }
        specMap: {
        	tensorflow: "tfReplicaSpecs"
        	pytorch:    "pytorchReplicaSpecs"
        	mxnet:      "mxReplicaSpecs"
        	mpi:        "mpiReplicaSpecs"
        	xgboost:    "xgbReplicaSpecs"
        }
        specTemplate: {
        	metadata: {
        		labels: {
        			if parameter.labels != _|_ {
        				parameter.labels
        			}
        			"app.oam.dev/component": context.name
        			"app.oam.dev/revision":  context.revision
        		}
        		if parameter.annotations != _|_ {
        			annotations: parameter.annotations
        		}
        	}

        	spec: {
        		containers: [{
        			name:  parameter.framework
        			image: parameter.image

        			if parameter["imagePullPolicy"] != _|_ {
        				imagePullPolicy: parameter.imagePullPolicy
        			}

        			if parameter["cmd"] != _|_ {
        				command: parameter.cmd
        			}

        			if parameter["env"] != _|_ {
        				env: parameter.env
        			}

        			if parameter["cpu"] != _|_ {
        				resources: {
        					limits: cpu:   parameter.cpu
        					requests: cpu: parameter.cpu
        				}
        			}

        			if parameter["memory"] != _|_ {
        				resources: {
        					limits: memory:   parameter.memory
        					requests: memory: parameter.memory
        				}
        			}

        			if parameter["gpu"] != _|_ {
        				resources: {
        					limits: "nvidia.com/gpu":   parameter.gpu
        					requests: "nvidia.com/gpu": parameter.gpu
        				}
        			}

        			volumeMounts: [ for v in parameter.storage {
        				{
        					if v.pvcRef != _|_ {
        						mountPath: v.pvcRef.mountPath
        						name:      v.pvcRef.name
        					}
        					if v.pvcRef == _|_ {
        						mountPath: v.mountPath
        						name:      v.name
        					}
        				}}]
        		}]

        		if parameter["imagePullSecrets"] != _|_ {
        			imagePullSecrets: [ for v in parameter.imagePullSecrets {
        				name: v
        			},
        			]
        		}

        		if parameter.storage != _|_ {
        			volumes: [ for v in parameter.storage {
        				{
        					if v.pvcRef != _|_ {
        						name: v.pvcRef.name
        						persistentVolumeClaim: claimName: v.pvcRef.name
        					}
        					if v.pvcRef == _|_ {
        						name: v.name
        						persistentVolumeClaim: claimName: v.name
        					}
        				}
        			}]
        		}
        	}
        }
        output: {
        	apiVersion: "kubeflow.org/v1"
        	kind:       kindMap[parameter.framework]
        	metadata: {
        		name:      context.name
        		namespace: context.namespace
        	}
        	spec: "\(specMap[parameter.framework])": {
        		if parameter.distribution != _|_ {
        			if parameter.distribution.ps > 0 && parameter.framework == "tensorflow" {
        				PS: {
        					replicas:      parameter.distribution.ps
        					restartPolicy: parameter.restartPolicy
        					template:      specTemplate
        				}
        			}
        			if parameter.distribution.master > 0 && parameter.framework == "pytorch" {
        				Master: {
        					replicas:      parameter.distribution.master
        					restartPolicy: parameter.restartPolicy
        					template:      specTemplate
        				}
        			}
        			if parameter.distribution.scheduler > 0 && parameter.framework == "mxnet" {
        				Scheduler: {
        					replicas:      parameter.distribution.scheduler
        					restartPolicy: parameter.restartPolicy
        					template:      specTemplate
        				}
        			}
        			if parameter.distribution.server > 0 && parameter.framework == "mxnet" {
        				Server: {
        					replicas:      parameter.distribution.server
        					restartPolicy: parameter.restartPolicy
        					template:      specTemplate
        				}
        			}
        			if parameter.distribution.launcher > 0 && parameter.framework == "mpi" {
        				Launcher: {
        					replicas:      parameter.distribution.launcher
        					restartPolicy: parameter.restartPolicy
        					template:      specTemplate
        				}
        			}
        			if parameter.distribution.worker > 0 {
        				Worker: {
        					replicas:      parameter.distribution.worker
        					restartPolicy: parameter.restartPolicy
        					template:      specTemplate
        				}
        			}
        		}
        		if parameter.distribution == _|_ {
        			Worker: {
        				replicas:      1
        				restartPolicy: parameter.restartPolicy
        				template:      specTemplate
        			}
        		}
        	}
        }
        outputs: {
        	for v in parameter.storage if v.pvcRef == _|_ {
        		"pvc-\(v.name)": {
        			apiVersion: "v1"
        			kind:       "PersistentVolumeClaim"
        			metadata: {
        				name:      v.name
        				namespace: context.namespace
        			}
        			spec: {
        				accessModes: v.accessModes
        				volumeMode:  v.volumeMode
        				if v.volumeName != _|_ {
        					volumeName: v.volumeName
        				}
        				if v.storageClassName != _|_ {
        					storageClassName: v.storageClassName
        				}

        				if v.resources.requests.storage == _|_ {
        					resources: requests: storage: "1Gi"
        				}
        				if v.resources.requests.storage != _|_ {
        					resources: requests: storage: v.resources.requests.storage
        				}
        				if v.resources.limits.storage != _|_ {
        					resources: limits: storage: v.resources.limits.storage
        				}
        				if v.dataSourceRef != _|_ {
        					dataSourceRef: v.dataSourceRef
        				}
        				if v.dataSource != _|_ {
        					dataSource: v.dataSource
        				}
        				if v.selector != _|_ {
        					dataSource: v.selector
        				}
        			}
        		}
        	}
        }
        parameter: {
        	// +usage=The training framework to use
        	framework: "tensorflow" | "pytorch" | "mpi" | "xgboost" | "mxnet"
        	// +usage=If you want to train the model in distributed mode, specify here
        	distribution?: {
        		// +usage=The number of PS replicas, suits for tensorflow model
        		ps?: int
        		// +usage=The number of Master replicas, suits for pytorch model
        		master?: int
        		// +usage=The number of Scheduler replicas, suits for mxnet model
        		scheduler?: int
        		// +usage=The number of Server replicas, suits for mxnet model
        		server?: int
        		// +usage=The number of Launcher replicas, suits for mpi model
        		launcher?: int
        		// +usage=The number of Worker replicas
        		worker?: int
        	}
        	restartPolicy: *"Never" | "OnFailure" | "Always"

        	// +usage=Specify the labels in the workload
        	labels?: [string]: string
        	// +usage=Specify the annotations in the workload
        	annotations?: [string]: string
        	// +usage=Which image would you like to use for your service
        	// +short=i
        	image: string
        	// +usage=Specify image pull policy for your service
        	imagePullPolicy?: "Always" | "Never" | "IfNotPresent"
        	// +usage=Specify image pull secrets for your service
        	imagePullSecrets?: [...string]
        	// +usage=Number of CPU units for the service, like `0.5` (0.5 CPU core), `1` (1 CPU core)
        	cpu?: string
        	// +usage=Specifies the attributes of the memory resource required for the container.
        	memory?: string
        	// +usage=Specifies the attributes of the gpu resource required for the container.
        	gpu?: string

        	// +usage=Define arguments by using environment variables
        	env?: [...{
        		// +usage=Environment variable name
        		name: string
        		// +usage=The value of the environment variable
        		value?: string
        		// +usage=Specifies a source the value of this var should come from
        		valueFrom?: {
        			// +usage=Selects a key of a secret in the pod's namespace
        			secretKeyRef?: {
        				// +usage=The name of the secret in the pod's namespace to select from
        				name: string
        				// +usage=The key of the secret to select from. Must be a valid secret key
        				key: string
        			}
        			// +usage=Selects a key of a config map in the pod's namespace
        			configMapKeyRef?: {
        				// +usage=The name of the config map in the pod's namespace to select from
        				name: string
        				// +usage=The key of the config map to select from. Must be a valid secret key
        				key: string
        			}
        		}
        	}]

        	storage?: [...{
        		// +usage=If you want to use a existed PVC, specify the PVC name and moutPath here
        		pvcRef?: {
        			name:      string
        			mountPath: string
        		}
        		name?:             string
        		mountPath?:        string
        		volumeMode:        *"Filesystem" | string
        		accessModes:       *["ReadWriteOnce"] | [...string]
        		storageClassName?: string
        		resources?: {
        			requests: storage: =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        			limits?: storage:  =~"^([1-9][0-9]{0,63})(E|P|T|G|M|K|Ei|Pi|Ti|Gi|Mi|Ki)$"
        		}
        		dataSourceRef?: {
        			name:     string
        			kind:     string
        			apiGroup: string
        		}
        		dataSource?: {
        			name:     string
        			kind:     string
        			apiGroup: string
        		}
        		selector?: {
        			matchLabels?: [string]: string
        			matchExpressions?: {
        				key: string
        				values: [...string]
        				operator: string
        			}
        		}
        	}]
        }
  status:
    customStatus: |-
      if context.output.status.conditions != _|_ {
      	conditions: context.output.status.conditions
      	message: "Job " + conditions[len(conditions)-1].type
      }
    healthPolicy: |-
      if context.output.status.conditions != _|_ {
      	conditions: context.output.status.conditions
      	isHealth: conditions[len(conditions)-1].type == "Succeeded"
      }
      if context.output.status.conditions == _|_ {
      	isHealth: false
      }
  workload:
    type: autodetects.core.oam.dev
